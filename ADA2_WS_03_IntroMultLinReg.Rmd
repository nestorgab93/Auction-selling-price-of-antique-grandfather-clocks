---
title: "Auction selling price of antique grandfather clocks"
author: "Nestor Pereira"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 5
    code_folding: show
    #df_print: paged
    #df_print: kable
    #toc_float: true
      #collapsed: false
      #smooth_scroll: TRUE
    theme: cosmo #spacelab #yeti #united #cosmo
    highlight: tango
  pdf_document:
    df_print: kable
fontsize: 12pt
geometry: margin=0.25in
always_allow_html: yes
---

<style>
/* HTML FORMATTING */
h1, .h1, h2, .h2, h3, .h3, h4, .h4, h5, .h5 {
  margin-top: 25px; /* space before each header */
  font-weight: bold; /* bold headers */
}
</style>

```{R, echo=FALSE}
# I set some GLOBAL R chunk options here.
#   (to hide this message add "echo=FALSE" to the code chunk options)

knitr::opts_chunk$set(comment = NA, message = FALSE, warning = FALSE, width = 100)
knitr::opts_chunk$set(fig.align = "center", fig.height = 4, fig.width = 6)

knitr::opts_chunk$set(cache = TRUE, autodep=TRUE)  #$
```

# Auction selling price of antique grandfather clocks

<!---
Data from http://www.statsci.org/data/general/auction.html
Mendenhall, W, and Sincich, TL (1993).
A Second Course in Statistics: Regression Analysis, 6th Edition, Prentice-Hall.
-->

The data include the selling price in pounds sterling at auction of 32 antique grandfather clocks,
  the age of the clock in years, and the number of people who made a bid.
In the sections below, describe the relationship between variables and develop a model
  for predicting selling `Price` given `Age` and `Bidders`.

```{R}
library(tidyverse)

dat_auction <- read_csv("ADA2_WS_03_auction.csv")
str(dat_auction)
summary(dat_auction)
```

## __(1 p)__ Scatterplot matrix
_In a scatterplot matrix below interpret the relationship between each pair of variables.
If a transformation is suggested by the plot (that is, because there is a curved relationship),
  also plot the data on the transformed scale and
  perform the following analysis on the transformed scale.
Otherwise indicate that no transformation is necessary._

```{R}
library(ggplot2)
library(GGally)
p <- ggpairs(dat_auction)
print(p)
```


### Solution

No transformation needed, since the correlation between variables looks linear.

## __(1 p)__ Correlation matrix
_Below is the correlation matrix and tests for the hypothesis that each correlation is equal to zero.
Interpret the hypothesis tests and relate this to the plot that you produced above._

```{R}
# correlation matrix and associated p-values testing "H0: rho == 0"
library(Hmisc)
rcorr(as.matrix(dat_auction))
```

### Solution

Only the correlation between age and number of bidders is not strong enought, showed by a low correlation coefficient and a p-value bigger than 0.05,meaning that there is no association between these two variables.

The correlation between price and bidder has a correlation coefficiento of 0.39 which might not look as a strong correlation but then looking at the p-value, we can see that the p_value is smaller than 0.05,therefore the null hypothesis is rejected, meaning that there is an association between theses two variables and the correlation is strong.

The correlation between price and age has a correlation coefficiento of 0.73 which is strong correlation. Also the p-value is smaller than 0.05,therefore the null hypothesis is rejected, meaning that there is an association between theses two variables and the correlation is strong.


## __(1 p)__ Plot interpretation
_Below are two plots.
The first has $y =$ Price, $x =$ Age, and colour = Bidders,
and the second has $y =$ Price, $x =$ Bidders, and colour = Age.
Interpret the relationships between all three variables, simultaneously.
For example, say how Price relates to Age,
then also how Price relates to Bidders conditional on Age being a specific value._

```{R, fig.height = 4, fig.width = 10, echo=FALSE}
dat_auction <-
  dat_auction %>%
  mutate(
    id = row_number()
  )

# ggplot: Plot the data with linear regression fit and confidence bands
library(ggplot2)
p1 <- ggplot(dat_auction, aes(x = Age, y = Price, label = id))
p1 <- p1 + geom_point(aes(colour = Bidders), size=3)
# plot labels next to points
p1 <- p1 + geom_text(hjust = 0.5, vjust = -0.5, alpha = 1/4, colour = 2)
# plot regression line and confidence band
p1 <- p1 + geom_smooth(method = lm)
p1 <- p1 + labs(title="Selling Price by Age with colored Bidders")
#print(p1)

# ggplot: Plot the data with linear regression fit and confidence bands
library(ggplot2)
p2 <- ggplot(dat_auction, aes(x = Bidders, y = Price, label = id))
p2 <- p2 + geom_point(aes(colour = Age), size=3)
# plot labels next to points
p2 <- p2 + geom_text(hjust = 0.5, vjust = -0.5, alpha = 1/4, colour = 2)
# plot regression line and confidence band
p2 <- p2 + geom_smooth(method = lm)
p2 <- p2 + labs(title="Selling Price by Bidders with colored Age")
#print(p2)

library(gridExtra)
grid.arrange(grobs = list(p1, p2), nrow=1)
```

### Solution

#### Price vs age

In the plot we can see that price increases when age of the clock increases

#### Price and bidder

In the plot we can see that price increases when number of bidders increases, but slower than the previous relationship explained between price and age.

## __(2 p)__ Multiple regression assumptions (assessing model fit)
_Below the multiple regression is fit.
Start by assessing the model assumptions by interpretting what you learn from each of the six plots._
_If assumptions are not met, attempt to address by transforming a variable and
restart at the beginning using the new transformed variable._

```{R}
# fit the simple linear regression model
lm_p_a_b <- lm(Price ~ Age + Bidders, data = dat_auction)
```

Plot diagnostics.
```{R, fig.height = 6, fig.width = 10, echo=FALSE}
# plot diagnistics
par(mfrow=c(2,3))
plot(lm_p_a_b, which = c(1,4,6))

plot(dat_auction$Age, lm_p_a_b$residuals, main="Residuals vs Age")
  # horizontal line at zero
  abline(h = 0, col = "gray75")

plot(dat_auction$Bidders, lm_p_a_b$residuals, main="Residuals vs Bidders")
  # horizontal line at zero
  abline(h = 0, col = "gray75")

# Normality of Residuals
library(car)
qqPlot(lm_p_a_b$residuals, las = 1, id = list(n = 3), main="QQ Plot")

## residuals vs order of data
#plot(lm_p_a_b$residuals, main="Residuals vs Order of data")
#  # horizontal line at zero
#  abline(h = 0, col = "gray75")
par(mfrow=c(1,1))
```

### Solution

From the diagnostic plots above,

  (1) Model redisuals and fitted ones dont follow any specific pattern
  (2) The cook distance shows which points could be considered outliers or more unusual to appear. In this case points 25,27 and 31, have higher cook's distances, but sine they are not unique they shouldnt be considered outliers, therefore removed from the data.
  (3) This plot shows the points which affect more to the model. Point 31 has a high leverage but looking at its cooks distance and points 25 and 27, we can see how its not necesart to remove it from the data
  (4) On this residual graph there is not an specific pattern followed by the model residuals respect the age.
  (5) looking at this 2D graph there not clear relationship, but looking it at the 3D plot, a slightly non linear relationship could be seen.
  (6) the QQ plot shows normality for the residuals.


## __(1 p)__ Added variable plots

_Use partial regression residual plots (added variable plots)
  to check for the need for transformations.
If linearity is not supported, address and restart at the beginning._

```{R, fig.height = 4, fig.width = 8, echo=FALSE}
library(car)
avPlots(lm_p_a_b, id.n=3)
```

### Solution

#### Partial regression plot 1

The partial plot shows a linear trend suggesting that no transformation is needed. The positive relationship seen here is consistent with the coefficient of age being positive in the multiple regression model

#### Partial regression plot 2

This next partial plot shows a linear trend, which could maybe bring some doubts about been slightly curvilinear, with a strong positive relationship between bidder and price, indicating that no transformation is needed here either.

## __(1 p)__ Multiple regression hypothesis tests
_State the hypothesis test and conclusion for each regression coefficient._

```{R}
# fit the simple linear regression model
lm_p_a_b <- lm(Price ~ Age + Bidders, data = dat_auction)
# use summary() to get t-tests of parameters (slope, intercept)
summary(lm_p_a_b)
```

### Solution

we run t-tests for the multiple linear regression parameters to find if the predictors are associated to the response variable.

The null hypothesis corresponds to the coefficient equal to zero. 

Since all the p values are smaller than 0.05, we reject the null hypothesis, meaning that the coefficients are different than zero, the t tests are significant and there is an association between the predictors and the response variable.


## __(1 p)__ Multiple regression interpret coefficients
_Interpret the coefficients of the multiple regression model._

### Solution

Age has a positive coefficient which increases the price by 12.7 pounds sterlings for ever extra year of age the clock has.
The number of bidders has also a positive coefficient which increases the price by 85 for every extra bidder a clock has.

The coeficient for age is smaller than the coefficient for bidders even thought the effect on the prediction is slightly stronger than the coefficient for bidders, shown with a larger correlation coefficient and a smaller p-value on the t-test.  This is because the age variable uses higher numbers and has a wider range.

The intercept is a high negative number which is only used to shift down the regression line and predict the price between reasonable ranges.A negative price wouldn't make sense and it could only happen with data outside our range since our data doesn't contain clocks under 108 years or clocks with less than 5 bidders. This shows that this regression model is only fitted for clocks with more than 108 years and more than 4 bidders.

## __(1 p)__ Multiple regression $R^2$
_Interpret the Multiple R-squared value._


### Solution

The R2 shows the variation of the response variable explained by both predictors. On this case, the R2 is 0.89, meaning 89% of the variation is explain by the predictors.

## __(1 p)__ Summary
_Summarize your findings in one sentence._

### Solution

We first studied the correlation between the variables age and number of bidders and obtained a non strong relationship. Since we are trying to predict the price from the predictor variables age and number of bidders, this initial correlation doesn't affect our model performance and doesn't concern us.

On this multiple linear regression both variables have a strong association with the predictor variable price. The years old of clock increase more the price than the number of bidders. Looking at the model adjusted R-squared, we can accurately predict the price of the clocks, since 89% of the price variation comes from this two predictor variables.



```{R}
## Aside: I generally recommend against 3D plots for a variety of reasons.
## However, here's a 3D version of the plot so you can visualize the surface fit in 3D.
## I will point out a feature in this plot that we wouldn't see in other plots
## and it would typically only be detected by careful consideration
## of a "more complicated" second-order model that includes curvature.

# library(rgl)
# library(car)
# scatter3d(Price ~ Age + Bidders, data = dat_auction)
```

